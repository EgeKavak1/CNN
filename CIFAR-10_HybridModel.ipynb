{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb6eeafb-58b2-4479-abfc-a0f803bf1d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gerekli kütüphaneler içe aktarıldı.\n",
      "Kullanılan cihaz: cuda\n",
      "Eğitim veri seti boyutu: 50000\n",
      "Test veri seti boyutu: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ege\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ege\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CNN özellik çıkarıcı (ResNet-18, son katman hariç) hazırlandı.\n",
      "Özellik çıkarıcı modeli kullanılan cihaz: cuda:0\n",
      "Özellikler 50000 görüntü için çıkarılıyor...\n",
      "  Batch 50/782 tamamlandı.\n",
      "  Batch 100/782 tamamlandı.\n",
      "  Batch 150/782 tamamlandı.\n",
      "  Batch 200/782 tamamlandı.\n",
      "  Batch 250/782 tamamlandı.\n",
      "  Batch 300/782 tamamlandı.\n",
      "  Batch 350/782 tamamlandı.\n",
      "  Batch 400/782 tamamlandı.\n",
      "  Batch 450/782 tamamlandı.\n",
      "  Batch 500/782 tamamlandı.\n",
      "  Batch 550/782 tamamlandı.\n",
      "  Batch 600/782 tamamlandı.\n",
      "  Batch 650/782 tamamlandı.\n",
      "  Batch 700/782 tamamlandı.\n",
      "  Batch 750/782 tamamlandı.\n",
      "Özellikler 10000 görüntü için çıkarılıyor...\n",
      "  Batch 50/157 tamamlandı.\n",
      "  Batch 100/157 tamamlandı.\n",
      "  Batch 150/157 tamamlandı.\n",
      "\n",
      "Özellik çıkarma tamamlandı.\n",
      "Eğitim özellikleri şekli: (50000, 512)\n",
      "Test özellikleri şekli: (10000, 512)\n",
      "\n",
      "Özellikler ve etiketler './hybrid_features' klasörüne kaydediliyor...\n",
      "Kaydetme tamamlandı.\n",
      "\n",
      "Seçilen Geleneksel ML Modeli: SVC\n",
      "SVC modeli eğitiliyor...\n",
      "SVC eğitimi tamamlandı.\n",
      "\n",
      "Geleneksel ML modeli test ediliyor...\n",
      "\n",
      "Hibrit Model (CNN Özellikleri + SVC) Test Doğruluğu: 0.8906\n",
      "\n",
      "Sınıflandırma Raporu:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane       0.90      0.92      0.91      1000\n",
      "  automobile       0.93      0.93      0.93      1000\n",
      "        bird       0.87      0.84      0.86      1000\n",
      "         cat       0.79      0.80      0.80      1000\n",
      "        deer       0.84      0.88      0.86      1000\n",
      "         dog       0.86      0.83      0.84      1000\n",
      "        frog       0.91      0.93      0.92      1000\n",
      "       horse       0.93      0.89      0.91      1000\n",
      "        ship       0.94      0.95      0.94      1000\n",
      "       truck       0.95      0.93      0.94      1000\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n",
      "\n",
      "Model 4 (Hibrit) süreci tamamlandı.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# MODEL 4: Hibrit CNN Özellik Çıkarıcı + Geleneksel ML Sınıflandırıcı\n",
    "# Bu notebook, bir CNN'in özellik çıkarıcı kısmını kullanarak görüntü özelliklerini çıkarır,\n",
    "# bu özellikleri ve etiketleri .npy dosyalarına kaydeder, ardından bu verilerle\n",
    "# geleneksel bir makine öğrenmesi modelini eğitir ve test eder.\n",
    "# =============================================================================\n",
    "\n",
    "# =============================================================================\n",
    "# 1. Gerekli Kütüphaneleri İçe Aktarma\n",
    "# =============================================================================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import os # Dosya işlemleri için\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(\"Gerekli kütüphaneler içe aktarıldı.\")\n",
    "\n",
    "# =============================================================================\n",
    "# 2. Cihazı Ayarlama (GPU veya CPU)\n",
    "# =============================================================================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Kullanılan cihaz: {device}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 3. Veri Dönüşümleri ve Yükleyiciler\n",
    "# CNN özellik çıkarıcısı için ImageNet boyutları ve normalizasyonu kullanılır.\n",
    "# =============================================================================\n",
    "# ImageNet standardı için dönüşümler\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), # ResNet/VGG gibi modeller 224x224 bekler\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # ImageNet normalizasyonu\n",
    "])\n",
    "\n",
    "# CIFAR-10 Veri Seti\n",
    "# download=True ilk çalıştırmada veriyi indirir\n",
    "train_data = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Veri Yükleyiciler\n",
    "# num_workers > 0 kullanmak veri yüklemeyi hızlandırabilir, ancak Jupyter'de dikkatli kullanılmalı\n",
    "# Jupyter'da sorun yaşarsanız num_workers=0 yapın\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=False, num_workers=2) # Shuffle=False özellik çıkarma sırasını korur\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"Eğitim veri seti boyutu: {len(train_data)}\")\n",
    "print(f\"Test veri seti boyutu: {len(test_data)}\")\n",
    "\n",
    "# CIFAR-10 sınıf isimleri (raporlama için)\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 4. CNN Özellik Çıkarıcıyı Hazırlama\n",
    "# ImageNet üzerinde önceden eğitilmiş bir ResNet-18 kullanacağız.\n",
    "# Son sınıflandırma katmanını çıkaracağız.\n",
    "# =============================================================================\n",
    "# ImageNet üzerinde önceden eğitilmiş ResNet-18 modelini yükle\n",
    "# pretrained=True, ImageNet ağırlıklarını yükler\n",
    "cnn_model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Özellik çıkarıcıyı oluşturma: ResNet'in 'fc' (fully connected) katmanını çıkar\n",
    "# Sequential(*list(cnn_model.children())[:-1]) ifadesi, modelin tüm alt katmanlarını alıp\n",
    "# sonuncusunu (yani 'fc'yi) listeden çıkarır ve bunlardan yeni bir Sequential modeli oluşturur.\n",
    "feature_extractor = torch.nn.Sequential(*list(cnn_model.children())[:-1])\n",
    "\n",
    "# Özellik çıkarıcıyı çıkarım moduna al\n",
    "feature_extractor.eval()\n",
    "\n",
    "# Özellik çıkarıcıyı seçilen cihaza taşı\n",
    "feature_extractor = feature_extractor.to(device)\n",
    "\n",
    "print(\"\\nCNN özellik çıkarıcı (ResNet-18, son katman hariç) hazırlandı.\")\n",
    "print(f\"Özellik çıkarıcı modeli kullanılan cihaz: {next(feature_extractor.parameters()).device}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 5. Veri Setinden Özellikleri ve Etiketleri Çıkarma\n",
    "# Bu adım uzun sürebilir. Çıkarılan veriler .npy olarak kaydedilecektir.\n",
    "# =============================================================================\n",
    "\n",
    "# Gradyan hesaplamayı kapat (çıkarım yaptığımız için gerek yok, bellekte tasarruf sağlar)\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "def extract_features(loader, model_fe, device):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "\n",
    "    print(f\"Özellikler {len(loader.dataset)} görüntü için çıkarılıyor...\")\n",
    "\n",
    "    for i, (images, labels) in enumerate(loader):\n",
    "        images = images.to(device)\n",
    "\n",
    "        # Özellik çıkarıcıdan geçir\n",
    "        features = model_fe(images)\n",
    "\n",
    "        # Özellik vektörünü düzleştir (flatten)\n",
    "        # ResNet'in AvgPool sonrası çıktısı (batch_size, num_features, 1, 1) şeklindedir.\n",
    "        # Bunu (batch_size, num_features) şekline düzleştiriyoruz.\n",
    "        features = torch.flatten(features, start_dim=1)\n",
    "\n",
    "        # CPU'ya taşı ve numpy dizisine çevir, listelere ekle\n",
    "        all_features.append(features.cpu().numpy())\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "        # İlerleme göstergesi (isteğe bağlı)\n",
    "        if (i + 1) % 50 == 0:\n",
    "            print(f\"  Batch {i+1}/{len(loader)} tamamlandı.\")\n",
    "\n",
    "    # Tüm batch'lerdeki verileri tek bir numpy dizisinde birleştir\n",
    "    all_features = np.concatenate(all_features, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    return all_features, all_labels\n",
    "\n",
    "# Eğitim ve test veri setleri için özellikleri çıkar\n",
    "train_features, train_labels = extract_features(train_loader, feature_extractor, device)\n",
    "test_features, test_labels = extract_features(test_loader, feature_extractor, device)\n",
    "\n",
    "print(\"\\nÖzellik çıkarma tamamlandı.\")\n",
    "print(f\"Eğitim özellikleri şekli: {train_features.shape}\")\n",
    "print(f\"Test özellikleri şekli: {test_features.shape}\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 6. Özellikleri ve Etiketleri .npy Dosyalarına Kaydetme\n",
    "# Bu adım, özellikleri bir kere çıkarıp sonraki çalıştırmalarda tekrar kullanmak için iyidir.\n",
    "# =============================================================================\n",
    "# Kaydedilecek dosya yollarını belirle\n",
    "output_dir = './hybrid_features'\n",
    "os.makedirs(output_dir, exist_ok=True) # Klasörü oluştur (varsa geç)\n",
    "\n",
    "train_features_file = os.path.join(output_dir, 'train_features.npy')\n",
    "train_labels_file = os.path.join(output_dir, 'train_labels.npy')\n",
    "test_features_file = os.path.join(output_dir, 'test_features.npy')\n",
    "test_labels_file = os.path.join(output_dir, 'test_labels.npy')\n",
    "\n",
    "# Numpy formatında kaydet\n",
    "print(f\"\\nÖzellikler ve etiketler '{output_dir}' klasörüne kaydediliyor...\")\n",
    "np.save(train_features_file, train_features)\n",
    "np.save(train_labels_file, train_labels)\n",
    "np.save(test_features_file, test_features)\n",
    "np.save(test_labels_file, test_labels)\n",
    "print(\"Kaydetme tamamlandı.\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 7. Kaydedilmiş Özellikleri ve Etiketleri Yükleme (İsteğe Bağlı)\n",
    "# Eğer notebook'u yeniden başlatırsanız, özellik çıkarma adımını atlayıp buradan devam edebilirsiniz.\n",
    "# =============================================================================\n",
    "# print(f\"\\nKayıtlı özellikler ve etiketler '{output_dir}' klasöründen yükleniyor...\")\n",
    "# loaded_train_features = np.load(train_features_file)\n",
    "# loaded_train_labels = np.load(train_labels_file)\n",
    "# loaded_test_features = np.load(test_features_file)\n",
    "# loaded_test_labels = np.load(test_labels_file)\n",
    "# print(\"Yükleme tamamlandı.\")\n",
    "#\n",
    "# # Yüklenen verileri kullanmak için değişkenlere atama\n",
    "# train_features = loaded_train_features\n",
    "# train_labels = loaded_train_labels\n",
    "# test_features = loaded_test_features\n",
    "# test_labels = loaded_test_labels\n",
    "# print(\"Yüklenen veriler atandı.\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 8. Geleneksel Makine Öğrenmesi Modelini Seçme, Eğitme ve Test Etme\n",
    "# Özellikler üzerinde geleneksel bir sınıflandırıcı eğiteceğiz.\n",
    "# =============================================================================\n",
    "\n",
    "# Kullanılacak Geleneksel ML modelini seçin ve başlatın\n",
    "# Alternatif: Destek Vektör Makinesi (SVC)\n",
    "model_ml = SVC(kernel='rbf', C=10, gamma='scale', random_state=42) # Ayarları deneme gerektirebilir\n",
    "print(f\"\\nSeçilen Geleneksel ML Modeli: {type(model_ml).__name__}\")\n",
    "print(\"SVC modeli eğitiliyor...\")\n",
    "# SVC eğitimi, Random Forest'a göre daha uzun sürebilir\n",
    "model_ml.fit(train_features, train_labels)\n",
    "print(\"SVC eğitimi tamamlandı.\")\n",
    "\n",
    "\n",
    "# Modeli test veri seti üzerinde değerlendir\n",
    "print(\"\\nGeleneksel ML modeli test ediliyor...\")\n",
    "predictions = model_ml.predict(test_features)\n",
    "\n",
    "# Performans metriklerini hesapla\n",
    "accuracy_ml = accuracy_score(test_labels, predictions)\n",
    "report_ml = classification_report(test_labels, predictions, target_names=classes) # CIFAR-10 sınıf isimlerini kullan\n",
    "\n",
    "print(f\"\\nHibrit Model (CNN Özellikleri + {type(model_ml).__name__}) Test Doğruluğu: {accuracy_ml:.4f}\")\n",
    "print(\"\\nSınıflandırma Raporu:\")\n",
    "print(report_ml)\n",
    "\n",
    "print(\"\\nModel 4 (Hibrit) süreci tamamlandı.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30072f0-48bc-4a74-b2e1-e7d33e08ce53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
